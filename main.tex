\documentclass[10pt,a4paper, notitlepage]{report}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{svg}
\usepackage{float}

\title{PhD Proposal}
\author{Irvin Aloise}


\begin{document}
\maketitle


\textbf{Keywords.} \textit{Mobile Robotics, SLAM, Multi-Agent and Multi-Robot Systems}


\section*{Summary of Proposal}
Todo


\section*{State of the Art}
In Robotics, an autonomous agent performs Simultaneous Localization and Mapping (SLAM) when it builds a map of the environment using different kind of sensors while localizing itself in the created map. Its core is a complex non-linear mathematical problem and it has been studied since 80s as explained in \cite{durrant2006simultaneous} and \cite{bailey2006simultaneous}. During this early stage, statistical basis that will constitute SLAM's core were investigated, while only during the late 90s probabilistic approaches started to spread. The works \cite{leonard1990dynamic} and \cite{dissanayake2001solution} used \textit{Extended Kalman Filters} to solve the problem while other approaches based on \textit{Expectation Maximization} algorithm were proposed by \cite{dellaert2003mcmc}, \cite{thrun2001probabilistic}. Filtering continued to gain popularity with \textit{Particle Filters} - employed in the remarkable work of \textit{Montemerlo et al.} \cite{montemerlo2002fastslam} - and its future refinements like \textit{Rao-Blackwellized Particle Filters} proposed by \cite{grisetti2005improving}, \cite{carlone2010rao} and \cite{tipaldi2007heterogeneous}.

Filtering-based approaches bring multiple drawbacks, like low computational efficiency and low accuracy due to problem's high nonlinearities; for these reasons, \textit{Maximum A Posteriori} (MAP) algorithms started to gain popularity and a step back to the solution of Lu \textit{et al.} given in \cite{lu1997globally} has been done. Exploiting more powerful computing resources, the problem can be formalized as an \textit{hyper-graph} where each node represents a robot pose or a landmark - a point of interest placed in the robot's surrounding - and each hyper-edge represents a constraint between a subset of nodes. 

Exploiting graph's topology, factor-graph optimization can achieve impressive performances as stated in the works of Dallaert \textit{et al.} \cite{dellaert2006square} and Kummerle \textit{et al.}  \cite{kummerle2011g}. MAP optimizers like \cite{kummerle2011g}, \cite{dellaert2012gtsam}, \cite{ceres-solver} and \cite{kaess2012isam2} are able to easily deal with huge graph and incremental optimization, delivering state-of-the-art performances both in speed and accuracy terms.

While SLAM's back-end performs map optimization, graph population is done by system's front-end, exploiting sensors' measurements. State-of-the-art systems usually acquire data from cameras (RGB or RGB-D) or 3D-LiDARs. The former ones in particular are gaining much attention since they are cheap and can be mounted basically on every kind of robot - in single or stereo configurations. Current benchmark systems for \textit{monocular visual SLAM} are \textit{ORB-SLAM} \cite{mur2015orb-slam} and \textit{LSD-SLAM} \cite{engel2014lsd-slam}, while for \textit{stereo configurations} it is impossible to ignore \textit{ORB-SLAM2} \cite{mur2017orb-slam2}. The former and the latter systems rely on the extraction of visual features from the scene, making them vulnerable to light changes or untextured scenes. \textit{LSD-SLAM} instead uses raw data to track robot motion and, thus, it is more robust to such weakness at the cost of more computational power needed to deliver real-time performances.

All those systems - even if they are able to produce significant results in terms of accuracy and speed - share two big drawbacks: the \textit{lack of adaption} to changes in the operating conditions and the lack of \textit{scalability} that would allow to cope with real-world scenarios. In this sense, the research community is still far from a solution, even if some early attempts are made. A possible approach to scalability that can be found in literature is \textit{node - edge sparsification} - \cite{kretzschmar2011graph-pruninig}, \cite{huang2013consistent} - that consists in pruning less informative node or factors following a suitable criterion. Another approach that can be found in literature is the \textit{parallelization of SLAM system} -  \cite{ni-dallaert2010nested-dissections}, \cite{ni-dallaert2007tectonicSAM}, \cite{grisetti2010hogman} - or \textit{multi-robot SLAM} - \cite{cunningham2013ddfSAM2}, \cite{lazaro2013mr-slam}. All those approaches are too early and still miss the point on long-term scalability issues like \textit{robustness}, the possibility to run with \textit{limited resources} and \textit{efficient data storage methods}. As for the adaptation, there very few proposal and many open problems - e.g. \textit{system's parameters tuning} or \textit{map representation} adaptation to the environment. An early investigation on this last topic is given by Wolcott \textit{et al.} in \cite{wolcott2014map-adaptation}.

\section*{Research Objectives}
Todo

\section*{Results, impacts and benefits}
Todo




\bibliographystyle{unsrt}
\bibliography{bibliography}

\end{document}